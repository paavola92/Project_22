{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FoML_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paavola92/Project_22/blob/main/FoML_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ya27paLge9Q"
      },
      "source": [
        "# Classifying German Traffic Signs using a Convolutional Neural Network\n",
        "\n",
        "This Colab notebook describes how we can build a CNN model for image classification on the GTSRB dataset.\n",
        "We will go through all the steps of working with such a dataset and model.\n",
        "This Colab notebook can be seen as a complete example of a typical project where some more advanced type of neural network is applied to structured data (such as images)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROHHDlQk1241"
      },
      "source": [
        "## Download and pre-process dataset\n",
        "The first thing we will have to do is to download the dataset itself.\n",
        "The dataset is hosted in an archive for public research data.\n",
        "Note that when we run code or handle files in Colab, this all happens on a virtual computer hosted in the cloud.\n",
        "The files are not downloaded to your local computer.\n",
        "\n",
        "Some steps of acquiring and pre-processing data can be easier to do using direct commands to the underlying linux environment, rather than using python code.\n",
        "In Colab, such commands can be run by writing a line of code starting with `!`.\n",
        "The code below will download the dataset as compressed files and extract these.\n",
        "It will also create and rename some directories to simplify the data loading in later steps.\n",
        "The downloaded data is already divided in a training and a test set.\n",
        "We will keep this split of the data.\n",
        "Later on we will additionally split the downloaded training images into training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dtm66Gh0cPi"
      },
      "source": [
        "!wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip\n",
        "!wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_Images.zip\n",
        "!wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_GT.zip\n",
        "\n",
        "!rm -rf test train\n",
        "!unzip -q GTSRB_Final_Training_Images.zip \n",
        "!unzip -q GTSRB_Final_Test_Images.zip \n",
        "!unzip -q GTSRB_Final_Test_GT.zip\n",
        "\n",
        "!mv GTSRB/Final_Test/Images test\n",
        "!mv GTSRB/Final_Training/Images train\n",
        "!rm -r GTSRB\n",
        "\n",
        "!mkdir train_cropped\n",
        "!mkdir test_cropped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_jQtllR2PH7"
      },
      "source": [
        "### Import python packages\n",
        "We will import a number of python packages that will be useful for building our model, data pre-processing and visualization.\n",
        "To introduce some of them briefly:\n",
        "\n",
        "* `PIL` is a library for working with images. We will use it for some pre-processing.\n",
        "* `numpy` you are likely already familiar with. Used for scientific computing in python.\n",
        "* `pandas` is a library for loading and working with large datasets.\n",
        "* `matplotlib` can be used to create different kinds of plots.\n",
        "* `Keras` is the deep learning library that we will use to create and train our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FImhvwp32ruN"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.random import set_seed as tf_set_seed\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "# Set random seeds for reproducability\n",
        "np.random.seed(42)\n",
        "tf_set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfcQLxHZ2J9A"
      },
      "source": [
        "### Crop images\n",
        "The raw images in the GTSRB dataset do not just contain the traffic sign itself, but also some of the background.\n",
        "To make the task easier for our model, we will pre-process the images by cropping out just the sign.\n",
        "An example of this pre-processing operation is shown below:\n",
        "\n",
        "| Before        | After       |\n",
        "| ------------- |-------------|\n",
        "| ![no_crop.png](data:image/png;base64,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)|![crop.png](data:image/png;base64,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) |\n",
        "\n",
        "The coordinates for cropping each image are provided in the dataset, so we simply have to read these from a list and crop each image accordingly.\n",
        "\n",
        "The function `crop_img_dir` iterates over all the images in `input_dir`, crops them and saves them in `output_dir`.\n",
        "Images in the training set are stored in 43 different directories, one for each class. \n",
        "We iterate over these and crop all of the images of each class.\n",
        "The test set images are all stored in the same directory, so we can crop all of these with one call to `crop_img_dir`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roEpONam2LpZ"
      },
      "source": [
        "def crop_img_dir(input_dir, output_dir, csv_name):\n",
        "    img_info = np.loadtxt(csv_name, delimiter=\";\", skiprows=1, dtype=str)\n",
        "\n",
        "    for img_i, info_row in enumerate(img_info):\n",
        "        # Row: img_name, _, _, x1, y1, x2, y2, _\n",
        "        img_name = info_row[0]\n",
        "        crop_coords = info_row[3:7].astype(int)\n",
        "\n",
        "        img_load_path = os.path.join(input_dir, img_name)\n",
        "        img_save_path = os.path.join(output_dir, img_name)\n",
        "        \n",
        "        img = Image.open(img_load_path)\n",
        "        img_cropped = img.crop(crop_coords)\n",
        "        img_cropped.save(img_save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcF8x7-s0u86"
      },
      "source": [
        "print(\"Pre-processing training data\")\n",
        "class_dirs = os.listdir(\"train\")\n",
        "n_classes = len(class_dirs)\n",
        "\n",
        "for class_i, dir_name in enumerate(class_dirs):\n",
        "    print(\"Pre-processing class {}/{}\".format(class_i+1, n_classes))\n",
        "    # Make output dir.\n",
        "    input_dir = os.path.join(\"train\", dir_name)\n",
        "    output_dir = os.path.join(\"train_cropped\", dir_name)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Crop all images\n",
        "    csv_name = os.path.join(input_dir,\"GT-{}.csv\".format(dir_name))\n",
        "    crop_img_dir(input_dir, output_dir, csv_name)\n",
        "\n",
        "print(\"Pre-processing test data\")\n",
        "crop_img_dir(\"test\", \"test_cropped\", \"GT-final_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_kBbGY087qn"
      },
      "source": [
        "We will also the define the list `CLASS_NAMES`, that contains descriptive names for each sign class.\n",
        "This will be useful when evaluating the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a7GOoU3r0fy"
      },
      "source": [
        "CLASS_NAMES = np.array([\n",
        "    \"Speed limit 20\",\n",
        "    \"Speed limit 30\",\n",
        "    \"Speed limit 50\",\n",
        "    \"Speed limit 60\",\n",
        "    \"Speed limit 70\",\n",
        "    \"Speed limit 80\",\n",
        "    \"End speed limit 80\",\n",
        "    \"Speed limit 100\",\n",
        "    \"Speed limit 120\",\n",
        "    \"No passing\",\n",
        "    \"No passing for over 3.5 tons\",\n",
        "    \"Right-of-way at the next intersection\",\n",
        "    \"Priority road\",\n",
        "    \"Yield\",\n",
        "    \"Stop\",\n",
        "    \"No vechiles\",\n",
        "    \"Vechiles over 3.5 tons prohibited\",\n",
        "    \"No entry\",\n",
        "    \"General caution\",\n",
        "    \"Dangerous curve to the left\",\n",
        "    \"Dangerous curve to the right\",\n",
        "    \"Double curve\",\n",
        "    \"Bumpy road\",\n",
        "    \"Slippery road\",\n",
        "    \"Road narrows on the right\",\n",
        "    \"Road work\",\n",
        "    \"Traffic signals\",\n",
        "    \"Pedestrians\",\n",
        "    \"Children crossing\",\n",
        "    \"Bicycles crossing\",\n",
        "    \"Beware of ice/snow\",\n",
        "    \"Wild animals crossing\",\n",
        "    \"End of all speed and passing limits\",\n",
        "    \"Turn right ahead\",\n",
        "    \"Turn left ahead\",\n",
        "    \"Ahead only\",\n",
        "    \"Go straight or right\",\n",
        "    \"Go straight or left\",\n",
        "    \"Keep right\",\n",
        "    \"Keep left\",\n",
        "    \"Roundabout mandatory\",\n",
        "    \"End of no passing\",\n",
        "    \"End of no passing by vechiles over 3.5 tons\",\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLhn_PzK9TV7"
      },
      "source": [
        "## Build and train model\n",
        "Now that we have downloaded and pre-processed the data we can start building our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTBfXtL-9-Re"
      },
      "source": [
        "### Define Keras datasets\n",
        "Before we can use our nicely pre-processed images we need to tell Keras how and where to load them.\n",
        "\n",
        "We first define an `ImageDataGenerator` which augments batches of images.\n",
        "If we would load the images without any augmentation the pixel values would be in the range $[0, 255]$. \n",
        "Using the `ImageDataGenerator` we here normalize these to $[0,1]$.\n",
        "We also tell this generator to reserve 20% of the data as a validation set.\n",
        "\n",
        "Using this generator we can then create the training and validation set objects. \n",
        "The images all have different sizes, but by setting  `target_size` we will here resize them all to 64$\\times$64 when they are loaded.\n",
        "Finally, we load the test set in a similar way. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ETynYJsWhZB"
      },
      "source": [
        "N_CLASSES = 43\n",
        "BATCH_SIZE = 128\n",
        "IMG_SIZE = 64\n",
        "\n",
        "img_gen = ImageDataGenerator(rescale=1./255., validation_split=0.2)\n",
        "train_set = img_gen.flow_from_directory(\"train_cropped\", class_mode=\"sparse\", \n",
        "                    batch_size=BATCH_SIZE, target_size=(IMG_SIZE, IMG_SIZE), \n",
        "                    seed=42, subset=\"training\")\n",
        "val_set = img_gen.flow_from_directory(\"train_cropped\", class_mode=\"sparse\", \n",
        "                    batch_size=BATCH_SIZE, target_size=(IMG_SIZE, IMG_SIZE), \n",
        "                    seed=42, subset=\"validation\")\n",
        "\n",
        "test_gen = ImageDataGenerator(rescale=1./255.)\n",
        "test_df = pd.read_csv(\"GT-final_test.csv\", sep=\";\")\n",
        "test_set = img_gen.flow_from_dataframe(test_df, directory=\"test_cropped\", \n",
        "            x_col=\"Filename\", y_col=\"ClassId\", class_mode=\"raw\", \n",
        "            batch_size=BATCH_SIZE, target_size=(IMG_SIZE, IMG_SIZE), \n",
        "            shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzJD26ffAq1s"
      },
      "source": [
        "### Define CNN model\n",
        "We can now finally define our model.\n",
        "The model is a convolutional neural network with 6 convolutional layers and 2 feed-forward (dense) layers.\n",
        "The convolutional layers all use 3$\\times$3 filters, zero-padding and ReLU activations.\n",
        "The stride is always 1, and to reduce the spatial dimension we instead use 3 [MaxPooling layers](https://keras.io/api/layers/pooling_layers/max_pooling2d/).\n",
        "To prevent overfitting we also include dropout layers in the feed-forward section of the network.\n",
        "\n",
        "After defining the architecture of a model in Keras we need to *compile* it, telling Keras how the model should be trained.\n",
        "We will use the Adam optimizer to minimize the multiclass cross-entropy cost function\n",
        "$$\n",
        "J(\\theta) = \\frac{1}{n} \\sum_{i=1}^n - \\ln(g_{y_i}(\\mathbf{x}_i ; \\theta))\n",
        "$$\n",
        "where $g(\\mathbf{x}_i ; \\theta)$ is the output of the network for input $\\mathbf{x}_i$ (in this case an image), after the softmax function has been applied.\n",
        "We also output a short summary of the full model that can be very useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdKyNCTZWviG"
      },
      "source": [
        "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "dropout_p = 0.5\n",
        "\n",
        "x = layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", \n",
        "                  activation=\"relu\")(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", \n",
        "                  activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=(3, 3))(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", \n",
        "                  activation=\"relu\")(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", \n",
        "                  activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=(3, 3))(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", \n",
        "                  activation=\"relu\")(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", \n",
        "                  activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=(3, 3))(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = layers.Dropout(dropout_p, seed=42)(x)\n",
        "x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "x = layers.Dropout(dropout_p, seed=42)(x)\n",
        "predictions = keras.layers.Dense(N_CLASSES, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.models.Model(inputs=inputs, outputs=predictions)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", \n",
        "              metrics=[\"accuracy\",])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OhZrn80F_kn"
      },
      "source": [
        "### Train model\n",
        "We are now ready to train our model. We will start by training it for 15 epochs. \n",
        "After each epoch the loss and accuracy on both the training and validation sets are logged."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VZ6Ew279GZ6"
      },
      "source": [
        "model.fit(train_set, epochs=15, validation_data=val_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM1vgOIcnZjk"
      },
      "source": [
        "By surveying the loss and accuracy on both datasets during training we can detect signs of over- or underfitting.\n",
        "If we are happy with the final validation accuracy, we can go on to evaluate our model on the test set.\n",
        "If not, we can go back and change the network architecture and/or hyperparameters related to the training process.\n",
        "In most cases, we would repeat this tuning many times until we reach results on the validation data that are deemd sufficient.\n",
        "\n",
        "In this notebook the network architecture and hyperparameters in the code have already been tuned to reasonable values for you.\n",
        "So we can now move on to evaluating the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvmp5XxR26Xy"
      },
      "source": [
        "### Evaluate model\n",
        "Run the code below to evaluate the model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGrYKg3k7qvd"
      },
      "source": [
        "model.evaluate(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpbqSYj6o69x"
      },
      "source": [
        "It is usually useful to also do some form of qualitative evaluation of the model.\n",
        "How this can be done depends on the type of data and problem at hand.\n",
        "For image data, it is useful to plot the images together with the model predictions.\n",
        "In this image classification problem we plot each image together with its true and predicted class.\n",
        "We also write out the proababilities output by the model for these classes.\n",
        "Run the code below to visualize a grid of predictions for the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09CenaOxcsxJ"
      },
      "source": [
        "PLOT_GRID=(4,3)\n",
        "n_img = PLOT_GRID[0]*PLOT_GRID[1]\n",
        "val_batch, val_label_batch = next(test_set)\n",
        "val_prediction = model.predict_on_batch(val_batch)\n",
        "\n",
        "fig, ax = plt.subplots(nrows=PLOT_GRID[0], ncols=PLOT_GRID[1], \n",
        "                       figsize=(5*PLOT_GRID[1],6*PLOT_GRID[0]))\n",
        "for img_ax, (img, probs, label) in zip(ax.flatten(), list(\n",
        "        zip(val_batch, val_prediction, val_label_batch))[:n_img]):\n",
        "    label = int(label)\n",
        "    pred_label = np.argmax(probs)\n",
        "    prob_of_true = probs[label]\n",
        "    prob_of_pred = probs[pred_label]\n",
        "\n",
        "    img_ax.imshow(img)\n",
        "    img_ax.set_title(\"Label: \\n {} (p={:.2}) \\n Prediction: \\n {} (p={:.2})\".format(\n",
        "        CLASS_NAMES[label], prob_of_true, CLASS_NAMES[pred_label], prob_of_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IThIrp44qsH9"
      },
      "source": [
        "You have now gone through a typical workflow of pre-processing image data, building and training a CNN model and finally evaluating the performance on a held-out test set.\n",
        "\n",
        "There are many additional steps one could consider taking in this process. \n",
        "Additional types of pre-processing could be useful.\n",
        "Many alternative network architectures could be considered.\n",
        "We could further tune the hyperparameters of the optimization algorithm to hopefully arrive at an even better solution.\n",
        "It is rarely possible to exhaustively explore all these options and typically we are happy with a model that is \"good enough\".\n",
        "\n",
        "The final part of this notebook is a small piece of code that can be used to upload and make predictions on new images.\n",
        "This will be used for one of the questions on the course platform.\n",
        "You can now return to the main course platform and answer the questions given there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9vdl0sg3LnP"
      },
      "source": [
        "## Predict on new images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaHkyCSYs7oq"
      },
      "source": [
        "Running the code cell below will create a button that opens a file upload dialog.\n",
        "Here you can upload one or multiple files that you want to make predictions for.\n",
        "These will be saved on the virtual machine that this notebook is executed on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdmGXdxvaOEC"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us5PutXstm4M"
      },
      "source": [
        "After uploading images above, run the code below to feed these through the model and make predictions.\n",
        "Each image is then plotted together with a bar chart displaying the top 5 predicted classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0541cq6CYtv-"
      },
      "source": [
        "N_BARS = 5\n",
        "PROB_TEXT_OFFSET = 0.05\n",
        "\n",
        "# Predict on uploaded images\n",
        "uploaded_file_names = uploaded.keys()\n",
        "new_imgs = [img_to_array(load_img(img_name, target_size=(IMG_SIZE, IMG_SIZE))) \n",
        "    for img_name in uploaded_file_names]\n",
        "new_img_batch = np.stack(new_imgs, axis=0)*(1./255.)\n",
        "new_img_pred = model.predict(new_img_batch)\n",
        "\n",
        "# Plot predictions\n",
        "for new_img, img_pred, img_name in zip(new_img_batch, \n",
        "                                       new_img_pred, uploaded_file_names):\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14,5))\n",
        "    fig.subplots_adjust(wspace=0.8)\n",
        "\n",
        "    # Draw image\n",
        "    ax[0].imshow(new_img)\n",
        "\n",
        "    # multiply with -1 to inverse sort order\n",
        "    sort_indexes = np.argsort(-img_pred)[:N_BARS] \n",
        "    top_probs = img_pred[sort_indexes]\n",
        "    top_classes = CLASS_NAMES[sort_indexes]\n",
        "\n",
        "    # Bar plot\n",
        "    bar_pos = np.arange(N_BARS) # Positions of bars on y-axis\n",
        "    ax[1].barh(bar_pos, width=top_probs, tick_label=top_classes)\n",
        "    ax[1].invert_yaxis()\n",
        "    ax[1].set_xlim(0,1)\n",
        "\n",
        "    # Write out probabilities\n",
        "    for (i, p) in enumerate(top_probs):\n",
        "        if p > 0.75:\n",
        "            align = \"right\"\n",
        "            x_pos = p - PROB_TEXT_OFFSET\n",
        "        else:\n",
        "            align = \"left\"\n",
        "            x_pos = p + PROB_TEXT_OFFSET\n",
        "        ax[1].text(x_pos, i, \"p={:.2}\".format(p), ha=align, \n",
        "                   va=\"center\", fontsize=13)\n",
        "\n",
        "    fig.suptitle(img_name, fontsize=20)\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}